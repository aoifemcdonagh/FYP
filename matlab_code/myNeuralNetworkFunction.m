function [Y,Xf,Af] = myNeuralNetworkFunction(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 09-Nov-2016 12:29:45.
% 
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
% 
%   X = 1xTS cell, 1 inputs over TS timsteps
%   Each X{1,ts} = 4xQ matrix, input #1 at timestep ts.
% 
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 3xQ matrix, output #1 at timestep ts.
% 
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

  % ===== NEURAL NETWORK CONSTANTS =====
  
  % Input 1
  x1_step1_xoffset = [4.3;2;1;0.1];
  x1_step1_gain = [0.555555555555555;0.833333333333333;0.338983050847458;0.833333333333333];
  x1_step1_ymin = -1;
  
  % Layer 1
  b1 = [2.507609111296405;-1.57989488678637;-0.93031981404579478;-1.8329805856803945;-0.34333069638191616;-1.3018588559196147;-0.86002321056651831;1.4413382258674912;-1.7020586653331791;2.4210877289397992];
  IW1_1 = [-1.6074541883734965 -1.6820248859303646 -0.34007712323111017 0.72655562214605574;1.2967510627603756 -1.0696049523991553 2.154183636075333 1.4960418652339511;1.3273313572847414 -1.7619269405465117 1.2543971271089775 -0.78139385207391032;0.45632824599998933 -0.0040594921201293349 -2.0934283671857505 -2.2084101683243778;1.8103581631688817 1.5649230020999456 0.056468919311274457 0.0082151371485249119;-0.29084634371824725 -0.097549596380597375 1.1417088119392529 3.0969344823430967;-0.56994369301820369 -1.4116048116402935 2.2393054079779686 -0.26139388738275904;0.58692350499453705 1.6303322364308759 1.7597940828853946 1.2779817921026166;-0.96499464634166721 -1.8558829964847334 1.4276146018709006 -0.61451245401578924;1.339688810461505 -0.39135013118774403 -1.3480143163308103 1.6279870611876586];
  
  % Layer 2
  b2 = [-0.88979303966778256;-0.0147229195664388;0.63234576278940358];
  LW2_1 = [-0.50899883052762818 0.50231336432270168 -1.3483278827617109 3.039626913037432 -0.26099675384896603 -1.7558145597721739 -0.89316192375273795 -0.55053266991489136 -0.76486385330490814 -0.39824301650381838;0.024481410794497904 -0.77932578513876016 -0.27904194114126118 -1.773422025815695 0.80366806585871386 -1.7148421032770651 -0.42276265140922153 0.36196554751669402 0.32609432571832808 0.18614180811603667;0.40477519929532452 2.0718328362261489 -0.28177677107408133 -0.44763636517371735 -0.49712659621569583 2.5981042321569947 1.6274785428859935 1.2929298489455441 1.0323062120057611 -0.73965523708493586];
  
  % ===== SIMULATION ========
  
  % Format Input Arguments
  isCellX = iscell(X);
  if ~isCellX, X = {X}; end;
  
  % Dimensions
  TS = size(X,2); % timesteps
  if ~isempty(X)
    Q = size(X{1},2); % samples/series
  else
    Q = 0;
  end
  
  % Allocate Outputs
  Y = cell(1,TS);
  
  % Time loop
  for ts=1:TS
  
    % Input 1
    Xp1 = mapminmax_apply(X{1,ts},x1_step1_gain,x1_step1_xoffset,x1_step1_ymin);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
  end
  
  % Final Delay States
  Xf = cell(1,0);
  Af = cell(2,0);
  
  % Format Output Arguments
  if ~isCellX, Y = cell2mat(Y); end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings_gain,settings_xoffset,settings_ymin)
  y = bsxfun(@minus,x,settings_xoffset);
  y = bsxfun(@times,y,settings_gain);
  y = bsxfun(@plus,y,settings_ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n)
  nmax = max(n,[],1);
  n = bsxfun(@minus,n,nmax);
  numer = exp(n);
  denom = sum(numer,1); 
  denom(denom == 0) = 1;
  a = bsxfun(@rdivide,numer,denom);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end
